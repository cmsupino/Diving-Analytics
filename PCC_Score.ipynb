{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9698194-9b80-4c85-8bdf-a93db478db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf871ab-3325-4d62-9bb9-27db68608607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "file_official=\"/Users/christinasupino/Desktop/DIVES/divingdata.csv\"\n",
    "df_official=pd.read_csv(file_official)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d91553-f203-41e5-9078-ba35380bed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Load PCC-created in \"ClipAndFrameCreation\" notebook\n",
    "df_pcc = pd.read_csv(\"/Users/christinasupino/Desktop/DIVES/DIVE_KEYPOINTS.csv\")\n",
    "\n",
    "#Extract LastName and DiveName from video filename\n",
    "df_pcc[\"LastName\"] = df_pcc[\"Video\"].str.split(\"_\").str[0].str.upper()\n",
    "df_pcc[\"DiveName\"] = (\n",
    "    df_pcc[\"Video\"].str.split(\"_\").str[1]\n",
    "    .str.replace(\".mp4\", \"\")\n",
    "    .str.replace(\"DIVE\", \"\")\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "#Filter to top 5 divers and top 5 dives\n",
    "top_divers = [\"Fung\", \"Brown\", \"Monroy Manriquez\", \"Hubert\", \"Palkhivala\"]\n",
    "top_dives = [\"301B\", \"201B\", \"103B\", \"403B\", \"105B\"]\n",
    "\n",
    "#Standardize official data\n",
    "df_official[\"LastName\"] = df_official[\"LastName\"].str.strip()\n",
    "df_official[\"DiveName\"] = df_official[\"DiveName\"].str.strip().str.upper()\n",
    "\n",
    "df_official_top = df_official[\n",
    "    df_official[\"LastName\"].isin(top_divers)&\n",
    "    df_official[\"DiveName\"].isin(top_dives)\n",
    "].copy()\n",
    "\n",
    "\n",
    "#Map PCC names to match official data\n",
    "name_map = {\n",
    "    \"FUNG\": \"Fung\",\n",
    "    \"BROWN\": \"Brown\",\n",
    "    \"MONROY\": \"Monroy Manriquez\",\n",
    "    \"HUBERT\": \"Hubert\",\n",
    "    \"PALKHIVALA\": \"Palkhivala\"\n",
    "}\n",
    "df_pcc[\"LastName\"] = df_pcc[\"LastName\"].map(name_map)\n",
    "\n",
    "\n",
    "#Check that everything matches\n",
    "print(set(df_pcc[\"LastName\"]) == set(df_official_top[\"LastName\"]))\n",
    "print(set(df_pcc[\"DiveName\"]) == set(df_official_top[\"DiveName\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa14d9ef-7e6b-42ea-93e3-952b7e46f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LastName DiveName        PCC\n",
      "0              Brown     103B   3.139802\n",
      "1              Brown     105B   9.233253\n",
      "2              Brown     201B   1.502711\n",
      "3              Brown     301B   2.176396\n",
      "4              Brown     403B   8.559236\n",
      "5               Fung     103B   2.077172\n",
      "6               Fung     105B   7.917267\n",
      "7               Fung     201B   2.023013\n",
      "8               Fung     301B   2.484125\n",
      "9               Fung     403B   7.982304\n",
      "10            Hubert     103B   2.103395\n",
      "11            Hubert     105B   9.562879\n",
      "12            Hubert     301B   2.903119\n",
      "13            Hubert     403B   8.000479\n",
      "14  Monroy Manriquez     103B   2.235449\n",
      "15  Monroy Manriquez     105B   8.528987\n",
      "16  Monroy Manriquez     201B   1.276812\n",
      "17  Monroy Manriquez     301B   2.851265\n",
      "18  Monroy Manriquez     403B   8.306766\n",
      "19        Palkhivala     103B   3.131635\n",
      "20        Palkhivala     105B  10.000000\n",
      "21        Palkhivala     201B   1.000000\n",
      "22        Palkhivala     301B   2.877607\n",
      "23        Palkhivala     403B   6.010769\n"
     ]
    }
   ],
   "source": [
    "#Load dive keypoints and phases\n",
    "df_keypoints = pd.read_csv(\"DIVE_KEYPOINTS.csv\")  \n",
    "df_phases = pd.read_csv(\"DIVE_PHASES.csv\")        \n",
    "        \n",
    "\n",
    "#Smoothness metric: captures continuity of movement by measuring jerk\n",
    "#Lower jerk = smoother motion\n",
    "def calculate_smoothness(coords):\n",
    "    vel = np.diff(coords, axis=0)\n",
    "    acc = np.diff(vel, axis=0)\n",
    "    jerk = np.diff(acc, axis=0)\n",
    "    mean_jerk = np.mean(np.abs(jerk)) if len(jerk) > 0 else 0\n",
    "    return 1 / (1 + mean_jerk)\n",
    "\n",
    "#Phase weights\n",
    "weights = {'takeoff': 0.3, 'flight': 0.4, 'entry': 0.3}\n",
    "\n",
    "#Store all raw metric values for normalization\n",
    "raw_scores = []\n",
    "all_std, all_smooth, all_entry_angle, all_symmetry, all_stability = [], [], [], [], []\n",
    "\n",
    "#Loop through each video and extract movement metrics separately for each phase\n",
    "for _, row in df_phases.iterrows():\n",
    "    video = row['Video']\n",
    "    last_name = video.split(\"_\")[0].upper()\n",
    "    dive_name = video.split(\"_\")[1].replace(\".mp4\",\"\").replace(\"DIVE\",\"\").upper()\n",
    "    last_name = name_map.get(last_name, last_name)\n",
    "\n",
    "    df_vid = df_keypoints[df_keypoints['Video'] == video]\n",
    "    keypoint_cols = [c for c in df_vid.columns if \"_x\" in c or \"_y\" in c or \"_z\" in c]\n",
    "\n",
    "    phase_scores = {}\n",
    "\n",
    "    #Extract the frame ranges corresponding to each phase\n",
    "    phase_frames = {\n",
    "        'takeoff': (row['StartFrame'], row['TakeoffFrame']),\n",
    "        'flight': (row['TakeoffFrame'], row['EntryFrame']),\n",
    "        'entry': (row['EntryFrame'], row['LastFrame'])\n",
    "    }\n",
    "\n",
    "    #Loop through phases to calculate each metric\n",
    "    for phase, (start_f, end_f) in phase_frames.items():\n",
    "        df_phase = df_vid[(df_vid['Frame'] >= start_f) & (df_vid['Frame'] <= end_f)]\n",
    "        coords = df_phase[keypoint_cols].to_numpy()\n",
    "\n",
    "        #Standrd deviation & smoothness\n",
    "        std_score = np.std(coords) if len(coords) > 1 else 0\n",
    "        smooth_score = calculate_smoothness(coords) if len(coords) > 1 else 0\n",
    "\n",
    "       #Entry angle: measures alignment at water entry\n",
    "        if phase == \"entry\" and len(df_phase) > 2:\n",
    "            sh_x = df_phase[['11_x','12_x']].mean(axis=1).mean()\n",
    "            sh_y = df_phase[['11_y','12_y']].mean(axis=1).mean()\n",
    "            an_x = df_phase[['27_x','28_x']].mean(axis=1).mean()\n",
    "            an_y = df_phase[['27_y','28_y']].mean(axis=1).mean()\n",
    "            dx = an_x - sh_x\n",
    "            dy = an_y - sh_y\n",
    "            angle = np.degrees(np.arctan2(dy, dx))\n",
    "            entry_angle_score = abs(90 - abs(angle)) #Closer to 0 = better\n",
    "        else:\n",
    "            entry_angle_score = None\n",
    "\n",
    "        #Symmetry: compares left vs right arm movement\n",
    "        if len(df_phase) > 2:\n",
    "            left_arm = df_phase[['11_x','11_y']].to_numpy()\n",
    "            right_arm = df_phase[['12_x','12_y']].to_numpy()\n",
    "            symmetry_score = np.mean(np.abs(left_arm - right_arm))\n",
    "        else:\n",
    "            symmetry_score = None\n",
    "\n",
    "        # Stability: measures positional consistency during the flight phase\n",
    "        if phase == \"flight\" and len(df_phase) > 2:\n",
    "            stability_score = np.mean(np.std(df_phase[keypoint_cols], axis=0))\n",
    "        else:\n",
    "            stability_score = None\n",
    "\n",
    "        #Store all metrics for specific phase\n",
    "        phase_scores[phase] = {\n",
    "            'std': std_score,\n",
    "            'smooth': smooth_score,\n",
    "            'entry_angle': entry_angle_score,\n",
    "            'symmetry': symmetry_score,\n",
    "            'stability': stability_score\n",
    "        }\n",
    "\n",
    "        #Collect for normalization\n",
    "        if std_score is not None: all_std.append(std_score)\n",
    "        if smooth_score is not None: all_smooth.append(smooth_score)\n",
    "        if entry_angle_score is not None: all_entry_angle.append(entry_angle_score)\n",
    "        if symmetry_score is not None: all_symmetry.append(symmetry_score)\n",
    "        if stability_score is not None: all_stability.append(stability_score)\n",
    "\n",
    "    #Store all metrics\n",
    "    raw_scores.append({\n",
    "        'LastName': last_name,\n",
    "        'DiveName': dive_name,\n",
    "        'PhaseScores': phase_scores\n",
    "    })\n",
    "\n",
    "#Normalization helper: rescales values to 0â€“1 so each metric contributes equally\n",
    "def normalize(arr):\n",
    "    arr = np.array(arr)\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "std_norm = normalize(all_std)\n",
    "smooth_norm = normalize(all_smooth)\n",
    "\n",
    "#Combine phase-level metrics into one PCC score per dive: mirroring judging criteria\n",
    "i_std = i_smooth= 0\n",
    "pcc_results = []\n",
    "\n",
    "for entry in raw_scores:\n",
    "    last_name = entry['LastName']\n",
    "    dive_name = entry['DiveName']\n",
    "    phase_scores = entry['PhaseScores']\n",
    "\n",
    "    pcc_total = 0\n",
    "\n",
    "    for phase in ['takeoff','flight','entry']:\n",
    "        std_component = 1 - std_norm[i_std]\n",
    "        smooth_component = smooth_norm[i_smooth]\n",
    "\n",
    "        # Combine the two\n",
    "        phase_score = 0.5 * std_component + 0.5 * smooth_component\n",
    "        pcc_total += weights[phase] * phase_score\n",
    "\n",
    "        i_std += 1\n",
    "        i_smooth += 1\n",
    "\n",
    "    #Multiply by difficulty\n",
    "    difficulty = df_official_top.loc[\n",
    "        (df_official_top['LastName']==last_name) & \n",
    "        (df_official_top['DiveName']==dive_name),\n",
    "        'Difficulty'\n",
    "    ].values[0]\n",
    "\n",
    "    pcc_weighted = pcc_total * difficulty\n",
    "    pcc_results.append({'LastName': last_name, 'DiveName': dive_name, 'PCC': pcc_weighted})\n",
    "\n",
    "#Final rescaling 1-10\n",
    "df_pcc_scores = pd.DataFrame(pcc_results)\n",
    "vals = df_pcc_scores['PCC'].values\n",
    "df_pcc_scores['PCC'] = 1 + 9 * (vals - vals.min()) / (vals.max() - vals.min())\n",
    "\n",
    "print(df_pcc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1226ae-5fc6-44f8-afea-5c7b4d3f42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate OfficialPoints per dive by FINA process\n",
    "judge_cols = [f\"Judge{i}\" for i in range(1, 8)]\n",
    "\n",
    "def calculate_official_points(row):\n",
    "    scores = np.array(row[judge_cols])\n",
    "    scores_sorted = np.sort(scores)\n",
    "    valid_scores = scores_sorted[2:-2]  #Discard 2 lowest and 2 highest\n",
    "    return valid_scores.sum() * row[\"Difficulty\"]\n",
    "    \n",
    "df_official_top[\"OfficialPoints\"]=df_official_top.apply(calculate_official_points,axis=1)\n",
    "\n",
    "\n",
    "#Rescale Official Points 1-10\n",
    "official_values = df_official_top[\"OfficialPoints\"].values\n",
    "official_min, official_max = official_values.min(), official_values.max()\n",
    "\n",
    "df_official_top[\"ScaledPoints\"] = 1 + 9 * (df_official_top[\"OfficialPoints\"] - official_min) / (official_max - official_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef898033-2bd3-4024-b100-d26099315224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall correlation (top 5 divers & dives): 0.8990423763132261\n",
      "Diver correlation:\n",
      "Fung: 0.969\n",
      "Brown: 0.948\n",
      "Monroy Manriquez: 0.982\n",
      "Hubert: 0.723\n",
      "Palkhivala: 0.899\n"
     ]
    }
   ],
   "source": [
    "#Merge PCC with official data\n",
    "df_merged_scaled = pd.merge(\n",
    "    df_official_top,\n",
    "    df_pcc_scores,\n",
    "    on=['LastName', 'DiveName']\n",
    ")\n",
    "df_merged_scaled.to_csv(\"df_merged_scaled.csv\", index=False)\n",
    "\n",
    "#Calculate overall correlation\n",
    "overall_corr = df_merged_scaled['PCC'].corr(df_merged_scaled['ScaledPoints'])\n",
    "\n",
    "#Calculate individual diver correlations\n",
    "diver_corrs = {\n",
    "    diver: df_merged_scaled[df_merged_scaled['LastName']==diver]['PCC'].corr(\n",
    "        df_merged_scaled[df_merged_scaled['LastName']==diver]['ScaledPoints']\n",
    "    )\n",
    "    for diver in top_divers\n",
    "}\n",
    "\n",
    "#Print results\n",
    "print(\"Overall correlation (top 5 divers & dives):\", overall_corr)\n",
    "print(\"Diver correlation:\")\n",
    "for diver, corr in diver_corrs.items():\n",
    "    print(f\"{diver}: {corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dive]",
   "language": "python",
   "name": "conda-env-dive-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
